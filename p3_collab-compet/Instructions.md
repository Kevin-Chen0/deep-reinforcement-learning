Go to [Report.ipynb](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/Report.ipynb) to see the training code, execution results, and report write-up. Dependency files include the following:

* [maddpg_agent.py](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/maddpg_agent.py.py): contains the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) that hosts of DDPG agents, OUNoise, Replay Buffer, and buffer_size/update_amount hyperparameters

* [ddpg_agent.py](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/ddpg_agent.py.py): contains the Deep Deterministic Policy Gradient (DDPG) Actor-Critic instantiations, OUNoise, and laerning_rate hyperparameters

* [model.py](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/model.py): contains the Neural Network (NN) architecture of the Actor-Critic

[test_run.py](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/test_run.py) also contains the source code from Report.ipynb but in a separate Python file. It is not needed to see or use the Report.

Please do not look at [Tennis.ipynb](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/Tennis.ipynb) as that just contains the template of the Report.
