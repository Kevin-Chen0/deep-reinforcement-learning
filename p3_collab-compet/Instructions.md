Go to [Report.ipynb](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/Report.ipynb) to see the training code, execution results, and report write-up. Dependency files include the following:

* [maddpg_agent.py](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/maddpg_agent.py.py): contains the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) list of DDPG agents

* [ddpg_agent.py](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/ddpg_agent.py.py): contains the Deep Deterministic Policy Gradient (DDPG) Actor-Critic instantiations, Replay Buffer, OUNoise, and hyperparameters

* [model.py](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/model.py): contains the Neural Network (NN) architecture of the Actor-Critic

[test_run.py](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p3_collab-compet/test_run.py) also contains the source code from Report.ipynb but in a separate Python file. It is not needed to see or use the Report.

Please do not look at [Continuous_Control.ipynb](https://github.com/Kevin-Chen0/deep-reinforcement-learning/blob/master/p2_continuous-control/Continuous_Control.ipynb) as that just contains the Report template.
